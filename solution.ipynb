{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'diabetes_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Inspect the dataset to get a sense of its structure\n",
    "data.head(), data.info(), data.describe(), data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing values and their percentages\n",
    "missing_values = data.isnull().sum()\n",
    "missing_percentage = (missing_values / len(data)) * 100\n",
    "\n",
    "# Create a summary DataFrame for missing values\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage (%)': missing_percentage\n",
    "}).sort_values(by='Percentage (%)', ascending=False)\n",
    "\n",
    "\n",
    "missing_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-clean the dataset\n",
    "numerical_columns = ['age', 'BMI', 'hypertension', 'diabetes_pedigree_function', 'weight', 'sleep_duration', 'family_diabetes' , 'pregnancies']\n",
    "categorical_columns = ['gender', 'diet_type', 'social_media_usage', 'stress_level', 'physical_activity_level', 'alcohol_consumption']\n",
    "target_column = 'diabetes'\n",
    "\n",
    "# Impute missing values based on column types and importance\n",
    "\n",
    "# 1. Drop columns with high missing percentages or less importance\n",
    "columns_to_drop = ['star_sign']  # Subject to review based on importance\n",
    "data_cleaned = data.drop(columns=columns_to_drop)\n",
    "\n",
    "# 2. Impute numerical columns with mean\n",
    "numerical_columns = ['age', 'BMI','hypertension','diabetes_pedigree_function', 'weight','family_diabetes', 'sleep_duration', 'pregnancies']\n",
    "for col in numerical_columns:\n",
    "    data_cleaned[col] = data_cleaned[col].fillna(data_cleaned[col].mean())\n",
    "\n",
    "# 3. Impute categorical columns with mode or \"Unknown\"\n",
    "categorical_columns = ['gender', 'social_media_usage','diet_type', 'stress_level', 'physical_activity_level', 'alcohol_consumption']\n",
    "for col in categorical_columns:\n",
    "   data_cleaned[col] =  data_cleaned[col].fillna(data_cleaned[col].mode()[0])\n",
    "\n",
    "# Impute missing values in categorical columns with \"Unknown\"\n",
    "categorical_columns = ['gender', 'social_media_usage','diet_type', 'stress_level', 'physical_activity_level', 'alcohol_consumption']\n",
    "for col in categorical_columns:\n",
    "    data_cleaned[col].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# 4. Drop rows with missing values in the target column (diabetes)\n",
    "data_cleaned = data_cleaned[data_cleaned['diabetes'].notna()]\n",
    "\n",
    "# Confirm changes\n",
    "missing_cleaned_summary = data_cleaned.isnull().sum()\n",
    "missing_cleaned_summary\n",
    "\n",
    "# Shape of cleaned data and total missing values count\n",
    "data_cleaned.shape, missing_cleaned_summary.sum()  \n",
    "\n",
    "#file can be used here as well\n",
    "# data_cleaned.to_csv('cleaned_diabetes_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Variable  Outliers Removed\n",
      "0                         age                 0\n",
      "1                         BMI               523\n",
      "2  diabetes_pedigree_function                 0\n",
      "3                      weight                 0\n",
      "4              sleep_duration              1936\n",
      "5                 pregnancies                 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Detect and remove outliers using IQR\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "\n",
    "# Outlier analysis and removal for significant numerical variables\n",
    "numerical_vars = ['age', 'BMI', 'diabetes_pedigree_function', 'weight', 'sleep_duration', 'pregnancies']\n",
    "outliers_summary = {}\n",
    "\n",
    "for column in numerical_vars:\n",
    "    # Detect outliers using IQR\n",
    "    outliers = detect_outliers_iqr(data, column)\n",
    "    outliers_summary[column] = len(outliers)\n",
    "    # Remove outliers from the dataset\n",
    "    data_cleaned = data_cleaned[~data_cleaned.index.isin(outliers.index)]\n",
    "\n",
    "# Create a summary of outliers removed\n",
    "outliers_df = pd.DataFrame(list(outliers_summary.items()), columns=['Variable', 'Outliers Removed'])\n",
    "print(outliers_df)\n",
    "data_cleaned.to_csv('cleaned_diabetes_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualize the distributions of cleaned numerical data\n",
    "numerical_vars = ['age', 'BMI', 'diabetes_pedigree_function', 'weight', 'sleep_duration', 'pregnancies']\n",
    "\n",
    "# Plot histograms for each numerical variable\n",
    "for column in numerical_vars:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(data[column], bins=30, edgecolor='k', alpha=0.7)\n",
    "    plt.title(f\"Distribution of {column}\")\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlations between numerical variables and the target (diabetes)\n",
    "correlation_matrix = data[numerical_vars + ['diabetes']].corr()\n",
    "\n",
    "# Extract correlations with the target variable (diabetes)\n",
    "diabetes_correlation = correlation_matrix['diabetes'].sort_values(ascending=False)\n",
    "\n",
    "# Visualize the correlations using a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "diabetes_correlation[:-1].plot(kind='bar', color='skyblue', edgecolor='k')\n",
    "plt.title(\"Correlation of Variables with Diabetes\")\n",
    "plt.xlabel(\"Variables\")\n",
    "plt.ylabel(\"Correlation Coefficient\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "diabetes_correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix for all numerical variables\n",
    "correlation_matrix = data[numerical_vars + ['diabetes']].corr()\n",
    "\n",
    "# Create a heatmap to visualize correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(\n",
    "    correlation_matrix, \n",
    "    annot=True, \n",
    "    fmt=\".2f\", \n",
    "    cmap=\"coolwarm\", \n",
    "    square=True, \n",
    "    cbar=True\n",
    ")\n",
    "plt.title(\"Correlation Heatmap of Numerical Variables\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m categorical_imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmost_frequent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Apply imputers to respective columns\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m X[numerical_features] \u001b[38;5;241m=\u001b[39m numerical_imputer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX\u001b[49m[numerical_features])\n\u001b[0;32m      9\u001b[0m X[categorical_features] \u001b[38;5;241m=\u001b[39m categorical_imputer\u001b[38;5;241m.\u001b[39mfit_transform(X[categorical_features])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Retry train-test split after imputing missing values\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values for numerical and categorical columns\n",
    "numerical_imputer = SimpleImputer(strategy=\"mean\")\n",
    "categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "# Apply imputers to respective columns\n",
    "X[numerical_features] = numerical_imputer.fit_transform(X[numerical_features])\n",
    "X[categorical_features] = categorical_imputer.fit_transform(X[categorical_features])\n",
    "\n",
    "# Retry train-test split after imputing missing values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Retry preprocessing and Logistic Regression pipeline\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = logreg_pipeline.predict(X_test)\n",
    "y_pred_proba = logreg_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "results = {\n",
    "    'Accuracy': accuracy,\n",
    "    'ROC AUC': roc_auc,\n",
    "    'Classification Report': classification_rep\n",
    "}\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[32], line 8\u001b[0m\n",
      "\u001b[0;32m      5\u001b[0m categorical_imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmost_frequent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Apply imputers to respective columns\u001b[39;00m\n",
      "\u001b[1;32m----> 8\u001b[0m X[numerical_features] \u001b[38;5;241m=\u001b[39m numerical_imputer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX\u001b[49m[numerical_features])\n",
      "\u001b[0;32m      9\u001b[0m X[categorical_features] \u001b[38;5;241m=\u001b[39m categorical_imputer\u001b[38;5;241m.\u001b[39mfit_transform(X[categorical_features])\n",
      "\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Retry train-test split after imputing missing values\u001b[39;00m\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values for numerical and categorical columns\n",
    "numerical_imputer = SimpleImputer(strategy=\"mean\")\n",
    "categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "# Apply imputers to respective columns\n",
    "X[numerical_features] = numerical_imputer.fit_transform(X[numerical_features])\n",
    "X[categorical_features] = categorical_imputer.fit_transform(X[categorical_features])\n",
    "\n",
    "# Retry train-test split after imputing missing values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Retry preprocessing and Logistic Regression pipeline\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = logreg_pipeline.predict(X_test)\n",
    "y_pred_proba = logreg_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "results = {\n",
    "    'Accuracy': accuracy,\n",
    "    'ROC AUC': roc_auc,\n",
    "    'Classification Report': classification_rep\n",
    "}\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
